<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>

<head>
<title>iss25-cargoproduct</title>

<!-- 
	<meta name="viewport" content="width=device-width, initial-scale=1"> 
-->	
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/foundation-sites@6.7.4/dist/css/foundation.min.css" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/foundation-sites@6.7.4/dist/js/foundation.min.js" crossorigin="anonymous"></script>
<link rel="stylesheet" type="text/css" href="./commons/resources/styles/templateISS.css">
<link rel="stylesheet" type="text/css" href="./commons/resources/styles/main.css">
<link rel="stylesheet" type="text/css" href="./commons/resources/styles/navbar.css">
<link rel="stylesheet" type="text/css" href="./commons/resources/styles/table.css">
<link rel="stylesheet" type="text/css" href="./commons/resources/styles/code.css">
<link rel="stylesheet" type="text/css" href="./css/mystyle.css">
</head>


<body>  

<div id="top">
<h1>cargoproduct</h1>
</div>  

<div class="body"> 


<h2>Il dominio</h2>
Si tratta di rappresentare e gestire prodotti da trasportare in un cargo.

<h3>Goal1</h3>
<ul>

<li>
Introdurre una classe di dominio che descrive le proprietà dei prodotti:
<a href=..//src//main//java//domain//Product.java target='code'>Product.java</a>


<center>
<img src="./img/ProductUML.JPG" alt="ProductUML" width="15%" height="15%">
</center>
</li><li>
Impostare una test unit con JUnit per verificare la correttezza della classe Product:
<a href=..//src//test//java//domain//TestProduct.java target='code'>TestProduct.java</a>
</li><li>
Verificare la produzione dei file di log nella cartella 
<a href=..//logs target='code'>logs</a>
</li>
</ul>

<h2>Goal2</h2>

Introdurre una classe di dominio che descrive la <b>logica di un servizio</b> di gestione 
dei prodotti da trasportare:
<a href=..//src//main//java//domain//ProductServiceLogic.java target='code'>ProductServiceLogic.java</a></li>
 
<p>
<ul>
<li>
Questa classe potrebbe diventare ora il nuovo main. In tal caso, modifico quindi la <b>mainclass</b> in <i>gradle.build</i>:
<tt>mainClassName    = 'main.java.domain.ProductServiceLogic'</tt>.
</li><li>
La classe realizza il contratto tipico di un servizio che realizza le operazioni <b>CRUD</b> 
(<i>Create, Read, Update, Delete</i>) sui prodotti: 
<a href=..//src//main//java//domain//ICrudOps.java target='code'>ICrudOps.java</a>.

</li><li>
Il modello introdotto nella prima versione del 'diario' 
<a href=cargoproduct_v0.html target='code'>cargoproduct_v0.html</a> potrebbe funzionare, ma 
<ks>introduce troppi vincoli</ks>.
</li><li>
Alla frase <i>La classe realizza due contratti</i> va sostituita la seguente:
</p><p>
la classe <ks>realizza il contratto</ks> <a href=..//src//main//java//domain//ICrudOps.java target='code'>ICrudOps.java</a>
e <mm>IPOTIZZA</mm> che il contratto <a href=..//src//main//java//domain//IStorage.java target='code'>IStorage.java</a>
<ks>debba essere rispettato dall'entità</ks> che si occupa di memorizzare i prodotti.
</p> 
</li><li>
La classe si avvale anche di supporti per la memorizzazione dei prodotti (Storage) cui accede tramite 
<mm>adapter</mm>, allo scopo di <ks>evitare dipendenze dirette</ks>.

</li>
</ul>

<center>
<img src="./img/ProductServiceLogicUML.JPG" alt="ProductServiceLogicUML" width="85%" height="85%"/>
</center>


<h3>Lo Storage</h3>

La registrazione dei prodotti avviene in un repository di cui si danno due versionI:

<ul>
<li>Una versione in memoria volatile, in forma di <i>hashTable</i>:
<a href=..//src//main//java//storage//StorageVolatile.java target='code'>StorageVolatile.java</a>
</li>
<li>Una versione in memoria permanente, basata sul database NoSql <ks>Mongo</ks>, che introdurremo in un momento successivo</li>
</ul>


La classe <a href=..//src//main//java//domain//adapter//AdapterStorage.java target='code'>AdapterStorage.java</a> 
realizza l'adapter che permette alla logica applicativa di non dipendere dalla specifica implementazione dello storage.

 <br/><br/>
<center>
<img src="./img/ProductServiceLogic.JPG" alt="ProductServiceLogic" width="55%" height="55%"/>
</center>
 
L'adapter realizza l'interfaccia <a href=..//src//main//java//domain//IStorage.java target='code'>IStorage.java</a>
che viene <ks>definita  a livello di dominio</ks>: 
in questo modo è la logica applicativa a dettare il contratto per l'uso dello storage.

<br/><br/>
<h2>Deployment</h2>
L'applicazione viene distribuita attraverso il file <i>jar</i> di nome <mm>cargoproduct-1.0.jar</mm>
prodotto mediante il comando: <pre>gradlew jar</pre>


Si può anche invocare il comando: <pre>gradlew buildFarJar</pre> che crea un file eseguibile che include
tutte le librerie necessarie al suo funzionamento.

Questo file eseguibile, piuttosto corposo, non è però necessario ai nostri scopi.

<br/><br/>
<h2>Lo stack ELK</h2>

Lo stack ELK soddisfa un'esigenza nello spazio di analisi dei dati di log.

<center>
<img src="./img/ELKArch.JPG" alt="ELKArch" width="55%" height="55%">
</center>

<ul>
<li><ks>Beats</ks> agenti che permettono il collect e l’invio dei dati verso lo stack Elastic.</li>
<li><ks>Logstash</ks> strumento open source che permette di raccogliere dati da una varietà di origini, 
trasformarli e inviarli alla destinazione desiderata. </li>
<li><ks>Elasticsearch</ks> è un motore di ricerca e analisi dei dati distribuito RESTful , basato su Apache Lucene che opera 
con documenti JSON senza schema. 
Dal 21 gennaio 2021 Elastic NV lo rende disponibile con la Licenza (non open source) Elastic o SSPL.</li>
<li><ks>Kibana</ks> è uno strumento di visualizzazione ed esplorazione dei dati utilizzato per analisi dei dati,
dei registri e serie temporali, monitoraggio delle applicazioni e casi d'uso di intelligenza operativa.</li>
</ul>

<h3>Attivazione dle sistema ELK</h3>

L'attivazione del sistema ELK avviene all'iterno di un container docker, organizzato come descritto nel file
<a href=..//docker-compose.yml target='code'>docker-compose.yml</a>
<br/><br/>

E' importante avere cura che i vari componenti  <em>facciano riferimento ad una stessa versione</em>.

<br/><br/>
<h4>Architettura del sistema</h4>

Si tratta di un sistema distribuito, in cui i componenti ELK sono 'microservizi' attivati tutti all'interno
di uno stesso container docker.
<br/><br/>
Il container del sistema ELK può essere attivato su un nodo diverso da quallo su cui gira l'applicazione.
L'indirizzo di questo nodo deve essere specificato nel file 
<tt>logback.xml</tt>, al posto di <b>localhost</b>.


<center>
<img src="./img/ProductServiceAndLog.JPG" alt="ProductServiceAndLog" width="50%" height="50%">
</center>


<br/><br/>
<h3>Il lato applicativo</h3>

<h4>Le librerie</h4>

Il file <a href=..//build.gradle target='code'>build.gradle</a> deve includere le seguenti librerie:

<pre>
dependencies {
    implementation 'ch.qos.logback:logback-classic:1.2.11'
    implementation("net.logstash.logback:logstash-logback-encoder:7.3")
}
</pre>

E' <em>importante usare versioni compatibili</em> delle ultime due librerie.
<br/><br/>
<h4>Il codice</h4>

Una classe applicativa (come <a href=..//src//main//java//domain//Product.java target='code'>Product.java</a> 
o <a href=..//src//main//java//domain//ProductServiceLogic.java target='code'>ProductServiceLogic.java</a>) 
genera i log utilizzando <ks>SLF4J/Logback</ks>, e invoca il metodo <ks>logger.info(s)</ks> dove s è una stringa JSON.
Ad esempio:

<pre>
logger.info("{\"productId\":10,\"name\":\"p10\",\"weight\":100}");
</pre>

<br/><br/>
<h4>logback.xml</h4>


Il file <a href=..//src//main//resources//logback.xml target='code'>logback.xml</a> 
introduce una specifica che indica che i log vengono inviati anche a Logstash tramite un appender che usa TCP.

<pre>
&lt;appender name="logstash" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
    &lt;destination>localhost:5044&lt;/destination>
    &lt;encoder class="net.logstash.logback.encoder.LogstashEncoder"/>
&lt;/appender>

    &lt;root level="info">      
        &lt;appender-ref ref="FILE" />
        &lt;appender-ref ref="LOGSTASH" /> 
    &lt;/root>
</pre>
<br/><br/>
<h4>logstash.conf</h4>

In base a quanto specificato in <i>logback.xml</i>, <i>Logstash</i> è stato configurato 
nel file <a href=..//src//main//resources//logstash.conf target='code'>logstash.conf</a>, come segue:

<ul>
<li><ks>parte di input</ks>: ascolta sulla porta <kc>5044</kc></li>
<li><ks>parte di output</ks>: invia i log a <i>Elasticsearch</i> via <b>http</b> sulla porta <kc>9200</kc> 
specificando  <ks>l'indice: cargo-logs-</ks>.<br/>
Il tag (opzionale) <kc>stdout</kc>  introduce  l'uso di un debugger
</li>

</li>
</ul>
 
<br/><br/>
<h3>Elasticsearch: i suoi document</h3>

I log processati da Logstash, sono inviati in Elasticsearch, che li memorizza in documenti JSON
all’interno dell'indice <ks>cargo-logs</ks>. Ad esempio:

<pre>
      {
        "_index" : "cargo-logs-",
        "_type" : "_doc",
        "_id" : "1",
        "_score" : 1.0,
        "_source" : {
          "productId" : 50,
          "weight" : 250,
          "name" : "p50"
      }
</pre>
<br/><br/>

<h3>Kibana: le sue funzioni</h3>

Accedendo a a Kibana (mediante browser su <kc>http://localhost:5601</kc>), 
è possibile creare un indice che corrisponde ai dati inviati, come <ks>cargo-logs-*</ks>. 
<br/><br/>
Con l’indice configurato, è possibile visualizzare i log in tempo reale, 
eseguire ricerche su determinati campi (ad esempio <tt>productId: “10”</tt>) 
o creare visualizzazioni e dashboard basate sui dati ricevuti. 
<br/><br/>
La visione di tutti i logs si ottiene come segue: 

<ol>
<li>Selezionare <tt>Analytics/Discover</tt></li>
<li>Creare l'index <tt>cargo-logs-*</tt></li>
<li>Selezionare il pulsante <tt>discover</tt></li>
</ol>

<h2>Interazioni con curl</h2>

Eseguendo (su un terminale <tt>Cygwin64</tt> ) il comando:
<pre>
curl -XGET "http://localhost:9200/cargo-logs-*/_search?pretty" -H "kbn-xsrf: reporting" -H "Content-Type: application/json" -d'
{
  "query": {
    "match_all": {}
  }
}'
</pre>

si ottiene (tra l'altro):

<pre>
      {
        "_index" : "cargo-logs-",
        "_type" : "_doc",
        "_id" : "AOY1C5IBp8-SE1mysHdh",
        "_score" : 1.0,
        "_source" : {
          "level" : "INFO",
          "port" : 35464,
          "thread_name" : "main",
          "logger_name" : "main.java.domain.Product",
          "host" : "172.23.0.1",
          "@timestamp" : "2024-09-19T16:55:19.465Z",
          "@version" : "1",
          "message" : """Product  | constructor json:{"productId":10,"name":"p10","weight":100}""",
          "level_value" : 20000
        }
</pre>

Eseguendo:

<pre>
curl -X POST "http://localhost:9200/cargo-logs-/_doc/1" -H 'Content-Type: application/json' -d'
{
  "productId": 50,
  "weight": 250,
  "name": "p50"
}'
</pre>

si ottiene:

<pre>
      {
        "_index" : "cargo-logs-",
        "_type" : "_doc",
        "_id" : "1",
        "_score" : 1.0,
        "_source" : {
          "productId" : 50,
          "weight" : 250,
          "name" : "p50"
      }
</pre>

Con il comando che segue possiamo eliminare un dato:

<pre>
 curl -X POST "http://localhost:9200/cargo-logs-*/_delete_by_query" -H 'Content-Type: application/json' -d'
 {
	"query": {
	  "match": {
		"productId":50
	   }
 }
 }'
</pre>







<div class="bottom">
	<div>By xxx email: xxx@studio.unibo.it
		<img src="./img/teacher.gif" alt="xxx" width="5%" height="5%">
	</div>  	
	GIT repo:<b><i>https://github.com/anatali/issLab2025</i></b> 	 
</div>
</body>
</html>
	